<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Kevin Liu" />


<title>Finite Difference</title>

<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Statistics by steps</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="archives.html">Archives</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Finite Difference</h1>
<h4 class="author">Kevin Liu</h4>
<h4 class="date">5/08/2020</h4>

</div>

<div id="TOC">
<ul>
<li><a href="#load-python-library" id="toc-load-python-library"><span class="toc-section-number">1</span> Load <code>python</code> library</a></li>
<li><a href="#derivative" id="toc-derivative"><span class="toc-section-number">2</span> Derivative</a></li>
<li><a href="#gradient" id="toc-gradient"><span class="toc-section-number">3</span> Gradient</a></li>
<li><a href="#hessian-matrix" id="toc-hessian-matrix"><span class="toc-section-number">4</span> Hessian Matrix</a></li>
<li><a href="#jacobian-matrix" id="toc-jacobian-matrix"><span class="toc-section-number">5</span> Jacobian Matrix</a></li>
<li><a href="#references" id="toc-references">References</a></li>
</ul>
</div>

<p>I write this page to record my study about numerical calculation of derivative, gradient, hessian matrix and jacobian matrix. Hope you find this helpful.</p>
<div id="load-python-library" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Load <code>python</code> library</h1>
<pre class="python"><code>import numpy as np</code></pre>
</div>
<div id="derivative" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Derivative</h1>
<p>Derivative of function <span class="math inline">\(f\)</span> at <span class="math inline">\(a\)</span> is defined as:</p>
<p><span class="math display" id="eq:e1">\[\begin{equation}
f^{\prime}(a)=\lim _{h \rightarrow 0} \frac{f(a+h)-f(a)}{h}
\tag{2.1}
\end{equation}\]</span></p>
<p>Finite difference is often used as an approximation of the derivative. Symetric derivative of function <span class="math inline">\(f\)</span> at point <span class="math inline">\(a\)</span> is defined as:</p>
<p><span class="math display" id="eq:e2">\[\begin{equation}
f^{\prime}(a)=\lim _{h \rightarrow 0} \frac{f(a+h)-f(a-h)}{2 h}
\tag{2.2}
\end{equation}\]</span></p>
<p>It is easy to find out why such approximation<a href="#eq:e2">(2.2)</a> is appropriate.
Taylor series of function <span class="math inline">\(f(x+h)\)</span> at point <span class="math inline">\(x\)</span> is defined as:</p>
<p><span class="math display" id="eq:e3">\[\begin{equation}
f(x+h)=f(x)+f^{\prime}(x) h+f^{\prime \prime}(x) \frac{h^{2}}{2}+f^{\prime \prime \prime}(x) \frac{h^{3}}{6}+\cdots
\tag{2.3}
\end{equation}\]</span></p>
<p>Similarly, Taylor series of function <span class="math inline">\(f(x-h)\)</span> at point <span class="math inline">\(x\)</span> is defined as:
<span class="math display" id="eq:e4">\[\begin{equation}
f(x-h)=f(x)-f^{\prime}(x) h+f^{\prime \prime}(x) \frac{h^{2}}{2}-f^{\prime \prime \prime}(x) \frac{h^{3}}{6}+\cdots
\tag{2.4}
\end{equation}\]</span></p>
<p>From <a href="#eq:e3">(2.3)</a>, we have the forward difference approximation:
<span class="math display" id="eq:e5">\[\begin{equation}
f^{\prime}(x)\approx\frac{f(x+h)-f(x)}{h}
\tag{2.5}
\end{equation}\]</span></p>
<p>From <a href="#eq:e4">(2.4)</a>, we get the backward difference approximation:
<span class="math display" id="eq:e6">\[\begin{equation}
f^{\prime}(x)\approx\frac{f(x)-f(x-h)}{h}
\tag{2.6}
\end{equation}\]</span></p>
<p>Combine <a href="#eq:e3">(2.3)</a> and <a href="#eq:e4">(2.4)</a>, we get the central difference approximation</p>
<p><span class="math display" id="eq:e7">\[\begin{equation}
f^{\prime}(x)\approx\frac{f(x+h)-f(x-h)}{2 h}
\tag{2.7}
\end{equation}\]</span></p>
<p>For example,</p>
<p><span class="math display">\[f(x) = x^2\]</span>
<span class="math display">\[f^{\prime}(x) = 2x \text{, } f^{\prime}(1)=2\]</span></p>
<pre class="python"><code>def derivative(func,initial,delta=1e-6):
  f = func
  f1 = f(initial+delta)
  f2 = f(initial-delta)
  output = (f1-f2)/(2*delta)
  return output

def f1(x):
  output = x**2
  return output

derivative(f1,initial=1)</code></pre>
<pre><code>## 2.000000000002</code></pre>
</div>
<div id="gradient" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Gradient</h1>
<p>The gradient of a a scalar-valued differentiable function <span class="math inline">\(f\)</span> of several variables, <span class="math inline">\(f: \mathbf{R}^{n} \rightarrow \mathbf{R}\)</span>, is a vector-valued function <span class="math inline">\(\nabla f: \mathbf{R}^{n} \rightarrow \mathbf{R}^{n}\)</span>, whose value at point <span class="math inline">\(p\)</span> is the vector whose components are the partial derivatives of <span class="math inline">\(f\)</span> at <span class="math inline">\(p\)</span>.</p>
<p><span class="math display" id="eq:e8">\[\begin{equation}
\nabla f(p)=\left[\begin{array}{c}
\frac{\partial f}{\partial x_{1}}(p) \\
\vdots \\
\frac{\partial f}{\partial x_{n}}(p)
\end{array}\right]
\tag{3.1}
\end{equation}\]</span></p>
<p>Define <span class="math inline">\(e_i = [I(1=i),...,I(n=i)]^T\)</span>, where <span class="math inline">\(I()\)</span> is indication function.</p>
<p><span class="math display" id="eq:e9">\[\begin{equation}
\nabla f(x)=\left[\begin{array}{c}
\frac{\partial f}{\partial x_{1}}(x) \\
\vdots \\
\frac{\partial f}{\partial x_{n}}(x)
\end{array}\right] \approx \frac{1}{2 h}\left[\begin{array}{c}
f\left(x+e_{1} h\right)-f\left(x-e_{1} h\right) \\
\vdots \\
f\left(x+e_{n} h\right)-f\left(x-e_{n} h\right)
\end{array}\right]
\tag{3.2}
\end{equation}\]</span></p>
<p>For example,</p>
<p><span class="math display">\[f(x,y,z)=x^2+y^2+2xyz\]</span>
<span class="math display">\[\nabla f(x,y,z)=
\left[\begin{array}{c}
2x+2yz \\
2y+2xz \\
2xy
\end{array}\right] \text{, } \nabla f(1,1,1)=
\left[\begin{array}{c}
4 \\
4 \\
2
\end{array}\right]\]</span></p>
<pre class="python"><code>def gradient(func, initial, delta=1e-6):
  f = func
  initial = np.array(initial, dtype=float)
  n = len(initial)
  output = np.zeros(n)
  for i in range(n):
    ei = np.zeros(n)
    ei[i] = 1
    f1 = f(initial + delta * ei)
    f2 = f(initial - delta * ei)
    output[i] = (f1-f2)/(2*delta)
  output = output.reshape(n,1)
  return output

def f2(x):
  x1 = x[0]
  x2 = x[1]
  x3 = x[2]
  output = x1**2 + x2**2 + 2*x1*x2*x3
  return output
  
gradient(f2,initial=[1,1,1])</code></pre>
<pre><code>## array([[4.],
##        [4.],
##        [2.]])</code></pre>
</div>
<div id="hessian-matrix" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Hessian Matrix</h1>
<p>Hessian matrix <span class="math inline">\(\mathbf{H}\)</span> of a scalar valued function <span class="math inline">\(f\)</span> is a square <span class="math inline">\(n\times n\)</span> matrix, defined as follows:</p>
<p><span class="math display" id="eq:e10">\[\begin{equation}
\mathbf{H}=\left[\begin{array}{cccc}
\frac{\partial^{2} f}{\partial x_{1}^{2}} &amp; \frac{\partial^{2} f}{\partial x_{1} \partial x_{2}} &amp; \cdots &amp; \frac{\partial^{2} f}{\partial x_{1} \partial x_{n}} \\
\frac{\partial^{2} f}{\partial x_{2} \partial x_{1}} &amp; \frac{\partial^{2} f}{\partial x_{2}^{2}} &amp; \cdots &amp; \frac{\partial^{2} f}{\partial x_{2} \partial x_{n}} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
\frac{\partial^{2} f}{\partial x_{n} \partial x_{1}} &amp; \frac{\partial^{2} f}{\partial x_{n} \partial x_{2}} &amp; \cdots &amp; \frac{\partial^{2} f}{\partial x_{n}^{2}}
\end{array}\right]
\tag{4.1}
\end{equation}\]</span></p>
<p>Equivalently, each element of hessian matrix can be defined as</p>
<p><span class="math display" id="eq:e11">\[\begin{equation}
\mathbf{H}_{i, j}=\frac{\partial^{2} f}{\partial x_{i} \partial x_{j}}
\tag{4.2}
\end{equation}\]</span></p>
<p>Using finite differences method,</p>
<p><span class="math display" id="eq:e12">\[\begin{equation}
\frac{\partial^{2} f}{\partial x_{i} \partial x_{j}} \approx
\frac{f(x+e_i h + e_j h)-f(x+e_i h - e_j h)-f(x-e_i h + e_j h)+f(x-e_i h - e_j h)}{4 h^{2}}
\tag{4.3}
\end{equation}\]</span></p>
<p>For example,
<span class="math display">\[f(x,y,z)=x^2+y^2+xy+z+xyz\]</span>
<span class="math display">\[\mathbf{H}=
\left[\begin{array}{ccc}
2 &amp; 1+z &amp; y\\
1 + z &amp; 2 &amp; x\\
y &amp; x &amp; 0
\end{array}\right]\text{, }\mathbf{H}(1,1,1)=
\left[\begin{array}{ccc}
2 &amp; 2 &amp; 1\\
2 &amp; 2 &amp; 1\\
1 &amp; 1 &amp; 0
\end{array}\right]\]</span></p>
<pre class="python"><code>def hessian(func,initial,delta=1e-3):
  f = func
  initial = np.array(initial, dtype=float)
  n = len(initial)
  output = np.matrix(np.zeros(n*n))
  output = output.reshape(n,n)
  for i in range(n):
    for j in range(n):
      ei = np.zeros(n)
      ei[i] = 1
      ej = np.zeros(n)
      ej[j] = 1
      f1 = f(initial + delta * ei + delta * ej)
      f2 = f(initial + delta * ei - delta * ej)
      f3 = f(initial - delta * ei + delta * ej)
      f4 = f(initial - delta * ei - delta * ej)
      numdiff = (f1-f2-f3+f4)/(4*delta*delta)
      output[i,j] = numdiff
  return output
  
def f3(x):
  x1 = x[0]
  x2 = x[1]
  x3 = x[2]
  output = x1**2 + x2**2 + x1*x2 + x3 + x1*x2*x3
  return output

hessian(f3,[1,1,1])</code></pre>
<pre><code>## matrix([[2., 2., 1.],
##         [2., 2., 1.],
##         [1., 1., 0.]])</code></pre>
</div>
<div id="jacobian-matrix" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Jacobian Matrix</h1>
<p>Jacobian matrix <span class="math inline">\(\mathbf{J}\)</span> of a vector-valued function in several variables is the matrix of all its first-order partial derivatives.</p>
<p><span class="math display" id="eq:e13">\[\begin{equation}
\mathbf{J} = \left[\begin{array}{ccc}
\frac{\partial f_{1}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial f_{1}}{\partial x_{n}} \\
\vdots &amp; \ddots &amp; \vdots \\
\frac{\partial f_{m}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial f_{m}}{\partial x_{n}}
\end{array}\right] =
\left[\begin{array}{c}
\nabla f_1(x)^T\\
\vdots\\
\nabla f_n(x)^T
\end{array}\right]
\tag{5.1}
\end{equation}\]</span></p>
<p>Jacobian matrix is row combination of transposed gradient of <span class="math inline">\(f_1,...,f_n\)</span>. Hence its approximation can be calculated based on <a href="#eq:e9">(3.2)</a></p>
<p>For example</p>
<p><span class="math display">\[\begin{bmatrix}
f_1(x,y)\\
f_2(x,y)\\
f_3(x,y)
\end{bmatrix}=
\begin{bmatrix}
x^2\\
y^2\\
xy
\end{bmatrix}\]</span></p>
<p><span class="math display">\[\mathbf{J}=
\begin{bmatrix}
2x &amp; 0\\
0 &amp; 2y\\
y &amp; x
\end{bmatrix}\text{, }
\mathbf{J}(1,2)=
\begin{bmatrix}
2 &amp; 0\\
0 &amp; 4\\
2 &amp; 1
\end{bmatrix}\]</span></p>
<pre class="python"><code>def jacobian(func,initial,delta=1e-3):
  f = func
  nrow = len(f(initial))
  ncol = len(initial)
  output = np.zeros(nrow*ncol)
  output = output.reshape(nrow,ncol)
  for i in range(nrow):
    for j in range(ncol):
      ej = np.zeros(ncol)
      ej[j] = 1
      dij = (f(initial+ delta * ej)[i] - f(initial- delta * ej)[i])/(2*delta)
      output[i,j] = dij
  return output
  
def f4(x):
  x1 = x[0]
  x2 = x[1]
  output = np.zeros(3)
  output[0] = x[0]**2
  output[1] = x[1]**2
  output[2] = x[0]*x[1]
  return output
  
jacobian(f4,[1,2])</code></pre>
<pre><code>## array([[2., 0.],
##        [0., 4.],
##        [2., 1.]])</code></pre>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<p><span class="citation">Bockelman (<a href="#ref-finite" role="doc-biblioref">2005</a>)</span></p>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-finite" class="csl-entry">
Bockelman, Brian. 2005. <a href="http://www.math.unl.edu/~s-bbockel1/833-notes/node23.html">http://www.math.unl.edu/~s-bbockel1/833-notes/node23.html</a>.
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
